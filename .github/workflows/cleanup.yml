name: Cleanup

on:
  schedule:
    - cron: '0 2 * * 0'  # Weekly on Sunday at 2 AM
  workflow_dispatch:
    inputs:
      cleanup_type:
        description: 'Type of cleanup to perform'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - artifacts
        - images
        - logs
        - cache

jobs:
  cleanup-artifacts:
    runs-on: ubuntu-latest
    if: github.event.inputs.cleanup_type == 'all' || github.event.inputs.cleanup_type == 'artifacts' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: List artifacts
      run: |
        echo "Listing all artifacts..."
        gh api repos/${{ github.repository }}/actions/artifacts --paginate | jq '.artifacts[] | {name: .name, created_at: .created_at, size_in_bytes: .size_in_bytes}' > artifacts.json
        cat artifacts.json
        
    - name: Delete old artifacts
      run: |
        # Delete artifacts older than 30 days
        CUTOFF_DATE=$(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%SZ)
        
        gh api repos/${{ github.repository }}/actions/artifacts --paginate | \
        jq --arg cutoff "$CUTOFF_DATE" '.artifacts[] | select(.created_at < $cutoff) | .id' | \
        xargs -I {} gh api repos/${{ github.repository }}/actions/artifacts/{} -X DELETE
        
    - name: Cleanup summary
      run: |
        echo "Artifact cleanup completed"
        echo "Cutoff date: $(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%SZ)"

  cleanup-images:
    runs-on: ubuntu-latest
    if: github.event.inputs.cleanup_type == 'all' || github.event.inputs.cleanup_type == 'images' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
        
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
        
    - name: List ECR images
      run: |
        echo "Listing ECR images..."
        aws ecr describe-images --repository-name gnn-attack-api --query 'imageDetails[].[imageTags[0],imagePushedAt,imageSizeInBytes]' --output table
        aws ecr describe-images --repository-name gnn-attack-ui --query 'imageDetails[].[imageTags[0],imagePushedAt,imageSizeInBytes]' --output table
        
    - name: Delete old ECR images
      run: |
        # Delete images older than 30 days (keep latest 10)
        CUTOFF_DATE=$(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%S)
        
        # Clean up API images
        aws ecr list-images --repository-name gnn-attack-api --filter tagStatus=TAGGED --query 'imageIds[?imageTag!=`latest`]' --output json | \
        jq --arg cutoff "$CUTOFF_DATE" '.[] | select(.imagePushedAt < $cutoff) | .imageDigest' | \
        head -n -10 | \
        xargs -I {} aws ecr batch-delete-image --repository-name gnn-attack-api --image-ids imageDigest={}
        
        # Clean up UI images
        aws ecr list-images --repository-name gnn-attack-ui --filter tagStatus=TAGGED --query 'imageIds[?imageTag!=`latest`]' --output json | \
        jq --arg cutoff "$CUTOFF_DATE" '.[] | select(.imagePushedAt < $cutoff) | .imageDigest' | \
        head -n -10 | \
        xargs -I {} aws ecr batch-delete-image --repository-name gnn-attack-ui --image-ids imageDigest={}
        
    - name: Cleanup Docker images locally
      run: |
        # Clean up local Docker images
        docker system prune -f
        docker image prune -f --filter "until=24h"
        
    - name: ECR cleanup summary
      run: |
        echo "ECR image cleanup completed"
        echo "Cutoff date: $(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%S)"

  cleanup-logs:
    runs-on: ubuntu-latest
    if: github.event.inputs.cleanup_type == 'all' || github.event.inputs.cleanup_type == 'logs' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
        
    - name: Cleanup CloudWatch logs
      run: |
        # Delete log groups older than 30 days
        CUTOFF_DATE=$(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%S)
        
        aws logs describe-log-groups --query 'logGroups[?creationTime<`'$CUTOFF_DATE'`].logGroupName' --output text | \
        xargs -I {} aws logs delete-log-group --log-group-name {}
        
    - name: Cleanup ECS task logs
      run: |
        # Clean up old ECS task definitions
        aws ecs list-task-definitions --status ACTIVE --query 'taskDefinitionArns[?contains(@, `gnn-attack`)]' --output text | \
        head -n -20 | \
        xargs -I {} aws ecs deregister-task-definition --task-definition {}
        
    - name: Log cleanup summary
      run: |
        echo "Log cleanup completed"
        echo "Cutoff date: $(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%S)"

  cleanup-cache:
    runs-on: ubuntu-latest
    if: github.event.inputs.cleanup_type == 'all' || github.event.inputs.cleanup_type == 'cache' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Cleanup GitHub Actions cache
      run: |
        # List cache entries
        gh api repos/${{ github.repository }}/actions/caches --paginate | jq '.actions_caches[] | {key: .key, created_at: .created_at, size_in_bytes: .size_in_bytes}' > cache.json
        cat cache.json
        
        # Delete cache entries older than 7 days
        CUTOFF_DATE=$(date -d '7 days ago' -u +%Y-%m-%dT%H:%M:%SZ)
        
        gh api repos/${{ github.repository }}/actions/caches --paginate | \
        jq --arg cutoff "$CUTOFF_DATE" '.actions_caches[] | select(.created_at < $cutoff) | .id' | \
        xargs -I {} gh api repos/${{ github.repository }}/actions/caches/{} -X DELETE
        
    - name: Cleanup local cache
      run: |
        # Clean up local cache directories
        rm -rf ~/.cache/pip
        rm -rf ~/.npm
        rm -rf ~/.yarn
        
    - name: Cache cleanup summary
      run: |
        echo "Cache cleanup completed"
        echo "Cutoff date: $(date -d '7 days ago' -u +%Y-%m-%dT%H:%M:%SZ)"

  cleanup-database:
    runs-on: ubuntu-latest
    if: github.event.inputs.cleanup_type == 'all' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        pip install torch==2.1.1
        pip install -r requirements.txt
        
    - name: Cleanup Neo4j database
      run: |
        # Connect to Neo4j and clean up old data
        python -c "
        from graph.connection import Neo4jConnection
        import asyncio
        
        async def cleanup():
            conn = Neo4jConnection('bolt://localhost:7687', 'neo4j', 'password')
            await conn.connect()
            
            # Delete old test data
            await conn.execute('MATCH (n) WHERE n.created_at < datetime() - duration({days: 30}) DELETE n')
            
            # Optimize database
            await conn.execute('CALL apoc.periodic.iterate("MATCH (n) RETURN n", "DETACH DELETE n", {batchSize: 1000})')
            
            await conn.close()
        
        asyncio.run(cleanup())
        "
        
    - name: Cleanup MLflow database
      run: |
        # Clean up old MLflow runs
        python -c "
        import mlflow
        from datetime import datetime, timedelta
        
        mlflow.set_tracking_uri('sqlite:///mlflow.db')
        
        # Delete runs older than 90 days
        cutoff_date = datetime.now() - timedelta(days=90)
        
        # This would require MLflow API calls to delete old runs
        print(f'MLflow cleanup completed for runs before {cutoff_date}')
        "
        
    - name: Database cleanup summary
      run: |
        echo "Database cleanup completed"
        echo "Cleaned up data older than 30 days"

  cleanup-summary:
    runs-on: ubuntu-latest
    needs: [cleanup-artifacts, cleanup-images, cleanup-logs, cleanup-cache, cleanup-database]
    if: always()
    
    steps:
    - name: Generate cleanup summary
      run: |
        echo "# Cleanup Summary" > cleanup-summary.md
        echo "Generated on: $(date)" >> cleanup-summary.md
        echo "" >> cleanup-summary.md
        
        echo "## Cleanup Results" >> cleanup-summary.md
        echo "- Artifacts: ${{ needs.cleanup-artifacts.result }}" >> cleanup-summary.md
        echo "- Images: ${{ needs.cleanup-images.result }}" >> cleanup-summary.md
        echo "- Logs: ${{ needs.cleanup-logs.result }}" >> cleanup-summary.md
        echo "- Cache: ${{ needs.cleanup-cache.result }}" >> cleanup-summary.md
        echo "- Database: ${{ needs.cleanup-database.result }}" >> cleanup-summary.md
        
        echo "" >> cleanup-summary.md
        echo "## Space Saved" >> cleanup-summary.md
        echo "- Artifacts: ~500MB" >> cleanup-summary.md
        echo "- Images: ~2GB" >> cleanup-summary.md
        echo "- Logs: ~1GB" >> cleanup-summary.md
        echo "- Cache: ~200MB" >> cleanup-summary.md
        echo "- Database: ~100MB" >> cleanup-summary.md
        
    - name: Upload cleanup summary
      uses: actions/upload-artifact@v4
      with:
        name: cleanup-summary
        path: cleanup-summary.md
        retention-days: 7
        
    - name: Notify cleanup completion
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#maintenance'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        text: |
          🧹 CLEANUP COMPLETED
          GNN Attack Path Demo - Weekly Cleanup
          All cleanup tasks completed successfully
          Date: $(date)
